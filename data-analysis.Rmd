---
title: Traffic Data Analysis
output: html_document
---

```{r}
library(ggplot2)
library(dplyr)
library(knitr)
```

# Data Processing

We first load our CSV file and take a glimpse at its contents.

```{r}
data.raw <- read.csv('all-semi-unique.csv')
glimpse(data.raw)
```

At first glance, we see that our raw data is composed of approximately 430k observations of 34 variables. Knowing that variables prefixed with **ad.** contain information relevant only to the application's advertising logic, we may safely drop them as they will not be used in our investigation.

```{r}
data.road <- data.raw %>% select(-(starts_with("ad.")))
```

Now that we have dropped variables that will not be of interest, we can investigate for variables that always carry a constant value in our observations

```{r}
data.road %>%
  sapply(unique) %>%
  sapply(length)
```

We can spot two variables that are always constant: **rd.cl** and **rd.rp.type**. Since they add no information to our data, we may safely discard them. We then take note of the format the *crawl_date* variable is in.

```{r}
data.road <- data.road %>% select(-(rd.cl), -(rd.rp.type))
head(data.road$crawl_date)
```

The crawl_date column currently contains a factor of different strings. We proceed to parse this into a more machine readable format as a column of time values.

```{r}
data.road$crawl_date <- 
  strptime(data.road$crawl_date, format = "%a %b %e %X UTC %Y", tz = "UTC") %>% 
  as.POSIXct()
head(data.road$crawl_date)
```

Upon further inspection of bey2ollak.com's response data: rd.rp.hr and rd.rp.mn are the time differences between the crawl_date and the report submission time. This means we can estimate the time of the response submission accurately down to a minute, which should be sufficient for our purposes.

```{r}
data.road <- data.road %>%
  mutate(report_time = as.POSIXct(round(crawl_date - (rd.rp.hr*60*60 + rd.rp.mn*60), "mins"))) %>%
  select(-c(rd.rp.mn, rd.rp.hr))
```

rd.rp.cmid is the id of the comment. ri is the road id.